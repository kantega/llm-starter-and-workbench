langchain4j.openai.chat-model.temperature=0.5
langchain4j.openai.timeout=60s

langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

langchain4j.ollama.chat-model.temperature=0.5
langchain4j.ollama.timeout=60s

langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true

#quarkus.log.category."dev.langchain4j".level=DEBUG
#quarkus.log.category."dev.ai4j.openai4j".level=DEBUG

llmwb.ollama.embedding-model.names=nomic-embed-text,mxbai-embed-large
llmwb.ollama.chat-model.names=gemma,llama2,mistral,mixtral,phi,qwen,openchat,normistral-7b-Q5_K_M

llmwb.openai.chat-model.names=gpt-3.5-turbo,gpt-3.5-turbo-16k,gpt-4,gpt-4-turbo-preview,gpt-4-32k
